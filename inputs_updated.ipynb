{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a01ZGTGewK3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc257a2e-2cac-4a76-c9a6-a2abef87488a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Enter file paths separated by commas: /content/Life Expectancy Data.csv , /content/Medical_insurance.csv/content/Medical_insurance.csv\n",
            "<class 'list'>\n",
            "Do you want to merge the files side-by-side? (yes/no): no\n",
            "Error loading /content/Life Expectancy Data.csv : Unsupported file format: csv \n",
            "Error loading  /content/Medical_insurance.csv/content/Medical_insurance.csv: [Errno 2] No such file or directory: ' /content/Medical_insurance.csv/content/Medical_insurance.csv'\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub\n",
        "import pandas as pd  # Import for handling DataFrames\n",
        "import json  # Import for reading JSON files\n",
        "import xml.etree.ElementTree as ET  # Import for parsing XML files\n",
        "from PIL import Image  # Import from PIL (Pillow) for handling image files\n",
        "from pydub import AudioSegment  # Import from pydub for handling audio files\n",
        "import cv2  # Import for handling video files\n",
        "import concurrent.futures  # Import for parallel execution\n",
        "\n",
        "def load_data(file_path):\n",
        "\n",
        "    file_extension = file_path.split('.')[-1].lower()  # Determine the file extension from the file path\n",
        "\n",
        "    try:\n",
        "        # Load CSV files into a DataFrame\n",
        "        if file_extension == 'csv':\n",
        "            return pd.read_csv(file_path)\n",
        "        # Load Excel files (both .xls and .xlsx) into a DataFrame,\n",
        "        elif file_extension in ['xls', 'xlsx']:\n",
        "            return pd.read_excel(file_path)\n",
        "        # Load JSON files into a Python object\n",
        "        elif file_extension == 'json':\n",
        "            with open(file_path, 'r') as f:\n",
        "                return json.load(f)\n",
        "        # Parse XML files and return the root of the XML tree\n",
        "        elif file_extension == 'xml':\n",
        "            tree = ET.parse(file_path)\n",
        "            return tree.getroot()\n",
        "        # Load HDF5 files into a DataFrame\n",
        "        elif file_extension in ['h5', 'hdf5']:\n",
        "            return pd.read_hdf(file_path)\n",
        "        # Load Feather files into a DataFrame\n",
        "        elif file_extension == 'feather':\n",
        "            return pd.read_feather(file_path)\n",
        "        # Read text files as plain text\n",
        "        elif file_extension == 'txt':\n",
        "            with open(file_path, 'r') as f:\n",
        "                return f.read()\n",
        "        # Open image files (JPG, JPEG) using PIL\n",
        "        elif file_extension in ['jpg', 'jpeg']:\n",
        "            return Image.open(file_path)\n",
        "        # Load audio files (MP3, WAV) using pydub\n",
        "        elif file_extension in ['mp3', 'wav']:\n",
        "            return AudioSegment.from_file(file_path)\n",
        "        # Open video files (MP4, AVI, MKV) using cv2\n",
        "        elif file_extension in ['mp4', 'avi', 'mkv']:\n",
        "            return cv2.VideoCapture(file_path)\n",
        "        else:\n",
        "            # Raise an error if the file format is not supported\n",
        "            raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
        "    except Exception as e:\n",
        "        # Print error message if an exception occurs during file loading\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def read_multiple_files(file_paths):\n",
        "    # List to store loaded data from each file\n",
        "    loaded_data = []\n",
        "\n",
        "    # Use ThreadPoolExecutor to load files concurrently\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Submit load_data tasks for each file path\n",
        "        future_to_file = {executor.submit(load_data, file_path): file_path for file_path in file_paths}\n",
        "        # Process each future as it completes\n",
        "        for future in concurrent.futures.as_completed(future_to_file):\n",
        "            file_path = future_to_file[future]\n",
        "            try:\n",
        "                # Retrieve the result of the future\n",
        "                data = future.result()\n",
        "                # Add the data to loaded_data if it is not None\n",
        "                if data is not None:\n",
        "                    loaded_data.append(data)\n",
        "            except Exception as e:\n",
        "                # Print error message if an exception occurs during future execution\n",
        "                print(f\"Error loading {file_path}: {e}\")\n",
        "\n",
        "    return loaded_data\n",
        "\n",
        "def merge_files_side_by_side(file_paths):\n",
        "    # Read multiple files and get a list of DataFrames\n",
        "    dfs = read_multiple_files(file_paths)\n",
        "    # Filter out only DataFrames from the list\n",
        "    dfs = [df for df in dfs if isinstance(df, pd.DataFrame)]\n",
        "\n",
        "    # Handle the case with zero or one DataFrame\n",
        "    if len(dfs) == 0:\n",
        "        return None  # or raise an error, depending on desired behavior\n",
        "    elif len(dfs) == 1:\n",
        "        return dfs[0]\n",
        "\n",
        "    # Concatenate DataFrames side-by-side (i.e., column-wise)\n",
        "    merged_df = pd.concat(dfs, axis=1)\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "def get_file_paths_from_input():\n",
        "    # Prompt user for input and split by comma\n",
        "    file_paths = input(\"Enter file paths separated by commas: \").split(',')\n",
        "    # Strip any extra whitespace from each file pathfile_paths = [file_path.strip() for file_path in file_paths]\n",
        "    return file_paths\n",
        "\n",
        "# Example usage\n",
        "file_paths = get_file_paths_from_input()  # Get the list of file paths from user input\n",
        "print(type(file_paths))\n",
        "\n",
        "if len(file_paths) > 1:\n",
        "    if_yes = input(\"Do you want to merge the files side-by-side? (yes/no): \")\n",
        "    if if_yes == \"yes\":\n",
        "        merged_df = merge_files_side_by_side(file_paths)  # Merge the files side-by-side\n",
        "        print(merged_df.head())\n",
        "    elif if_yes == \"no\":\n",
        "        x = read_multiple_files(file_paths)  # Read the files individually\n",
        "        for idx, file_data in enumerate(x):\n",
        "            variable_name = f\"file_{idx+1}\"\n",
        "            globals()[variable_name] = file_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yKhUp9jLmyx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsHwGlYgLmvY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqLE81XWLmtA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDf6l-sULmID",
        "outputId": "9e627874-2176-48c6-84b4-d7501da3a6c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pydub==1.0.0 (from versions: 0.1, 0.1.1, 0.2, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.2.5, 0.2.6, 0.2.7, 0.2.8, 0.2.9, 0.3, 0.4, 0.4.1, 0.4.2, 0.5.0, 0.5.1, 0.5.2, 0.5.3, 0.5.4, 0.5.5, 0.5.6, 0.6.0, 0.6.1, 0.6.2, 0.6.3, 0.7.0, 0.7.1, 0.8.0, 0.8.1, 0.8.2, 0.8.3, 0.9.0, 0.9.1, 0.9.2, 0.9.3, 0.9.4, 0.9.5, 0.10.0, 0.11.0, 0.12.0, 0.14.0, 0.14.1, 0.14.2, 0.15.0, 0.16.0, 0.16.1, 0.16.2, 0.16.3, 0.16.4, 0.16.5, 0.16.6, 0.16.7, 0.17.0, 0.18.0, 0.19.0, 0.20.0, 0.21.0, 0.22.0, 0.22.1, 0.23.0, 0.23.1, 0.24.0, 0.24.1, 0.25.0, 0.25.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pydub==1.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "!pip install pydub==1.0.0\n",
        "import pandas as pd\n",
        "import json\n",
        "import xml.etree.ElementTree as ET\n",
        "from PIL import Image\n",
        "from pydub import AudioSegment\n",
        "import cv2\n",
        "import concurrent.futures\n",
        "\n",
        "def load_data(file_path):\n",
        "    file_extension = file_path.split('.')[-1].lower()\n",
        "    try:\n",
        "        if file_extension == 'csv':\n",
        "            return pd.read_csv(file_path)\n",
        "        elif file_extension in ['xls', 'xlsx']:\n",
        "            return pd.read_excel(file_path)\n",
        "        elif file_extension == 'json':\n",
        "            with open(file_path, 'r') as f:\n",
        "                return json.load(f)\n",
        "        elif file_extension == 'xml':\n",
        "            tree = ET.parse(file_path)\n",
        "            return tree.getroot()\n",
        "        elif file_extension in ['h5', 'hdf5']:\n",
        "            return pd.read_hdf(file_path)\n",
        "        elif file_extension == 'feather':\n",
        "            return pd.read_feather(file_path)\n",
        "        elif file_extension == 'txt':\n",
        "            with open(file_path, 'r') as f:\n",
        "                return f.read()\n",
        "        elif file_extension in ['jpg', 'jpeg', 'png', 'gif', 'bmp']:\n",
        "            return Image.open(file_path)\n",
        "        elif file_extension in ['mp3', 'wav', 'ogg', 'flac']:\n",
        "            return AudioSegment.from_file(file_path)\n",
        "        elif file_extension in ['mp4', 'avi', 'mkv', 'mov']:\n",
        "            return cv2.VideoCapture(file_path)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def read_multiple_files(file_paths):\n",
        "    loaded_data = []\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        future_to_file = {executor.submit(load_data, file_path): file_path for file_path in file_paths}\n",
        "        for future in concurrent.futures.as_completed(future_to_file):\n",
        "            file_path = future_to_file[future]\n",
        "            try:\n",
        "                data = future.result()\n",
        "                if data is not None:\n",
        "                    loaded_data.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {file_path}: {e}\")\n",
        "    return loaded_data\n",
        "\n",
        "def merge_files_side_by_side(file_paths):\n",
        "    dfs = read_multiple_files(file_paths)\n",
        "    dfs = [df for df in dfs if isinstance(df, pd.DataFrame)]\n",
        "    if len(dfs) == 0:\n",
        "        return None\n",
        "    elif len(dfs) == 1:\n",
        "        return dfs[0]\n",
        "    merged_df = pd.concat(dfs, axis=1)\n",
        "    return merged_df\n",
        "\n",
        "def get_file_paths_from_input():\n",
        "    file_paths = input(\"Enter file paths separated by commas: \").split(',')\n",
        "    file_paths = [file_path.strip() for file_path in file_paths]\n",
        "    return file_paths\n",
        "\n",
        "file_paths = get_file_paths_from_input()\n",
        "print(type(file_paths))\n",
        "\n",
        "if len(file_paths) > 1:\n",
        "    if_yes = input(\"Do you want to merge the files side-by-side? (yes/no): \")\n",
        "    if if_yes.lower() == \"yes\":\n",
        "        merged_df = merge_files_side_by_side(file_paths)\n",
        "        if merged_df is not None:\n",
        "          display(merged_df)\n",
        "    elif if_yes.lower() == \"no\":\n",
        "        loaded_files = read_multiple_files(file_paths)\n",
        "        for idx, file_data in enumerate(loaded_files):\n",
        "            variable_name = f\"file_{idx+1}\"\n",
        "            globals()[variable_name] = file_data\n",
        "            print(f\"{variable_name}:\")\n",
        "            if isinstance(file_data, pd.DataFrame):\n",
        "                display(file_data)\n",
        "            else:\n",
        "                print(file_data)\n",
        "else:\n",
        "    loaded_files = read_multiple_files(file_paths)\n",
        "    for idx, file_data in enumerate(loaded_files):\n",
        "        pass # Add your code here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "import pandas as pd  # Import for handling DataFrames\n",
        "import json  # Import for reading JSON files\n",
        "import xml.etree.ElementTree as ET  # Import for parsing XML files\n",
        "from PIL import Image  # Import from PIL (Pillow) for handling image files\n",
        "from pydub import AudioSegment  # Import from pydub for handling audio files\n",
        "import cv2  # Import for handling video files\n",
        "import concurrent.futures  # Import for parallel execution\n",
        "\n",
        "def load_data(file_path):\n",
        "    file_extension = file_path.split('.')[-1].lower()  # Determine the file extension from the file path\n",
        "\n",
        "    try:\n",
        "        # Load CSV files into a DataFrame\n",
        "        if file_extension == 'csv':\n",
        "            return pd.read_csv(file_path)\n",
        "        # Load Excel files (both .xls and .xlsx) into a DataFrame\n",
        "        elif file_extension in ['xls', 'xlsx']:\n",
        "            return pd.read_excel(file_path)\n",
        "        # Load JSON files into a Python object\n",
        "        elif file_extension == 'json':\n",
        "            with open(file_path, 'r') as f:\n",
        "                return json.load(f)\n",
        "        # Parse XML files and return the root of the XML tree\n",
        "        elif file_extension == 'xml':\n",
        "            tree = ET.parse(file_path)\n",
        "            return tree.getroot()\n",
        "        # Load HDF5 files into a DataFrame\n",
        "        elif file_extension in ['h5', 'hdf5']:\n",
        "            return pd.read_hdf(file_path)\n",
        "        # Load Feather files into a DataFrame\n",
        "        elif file_extension == 'feather':\n",
        "            return pd.read_feather(file_path)\n",
        "        # Read text files as plain text\n",
        "        elif file_extension == 'txt':\n",
        "            with open(file_path, 'r') as f:\n",
        "                return f.read()\n",
        "        # Open image files (JPG, JPEG) using PIL\n",
        "        elif file_extension in ['jpg', 'jpeg']:\n",
        "            return Image.open(file_path)\n",
        "        # Load audio files (MP3, WAV) using pydub\n",
        "        elif file_extension in ['mp3', 'wav']:\n",
        "            return AudioSegment.from_file(file_path)\n",
        "        # Open video files (MP4, AVI, MKV) using cv2\n",
        "        elif file_extension in ['mp4', 'avi', 'mkv']:\n",
        "            return cv2.VideoCapture(file_path)\n",
        "        else:\n",
        "            # Raise an error if the file format is not supported\n",
        "            raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
        "    except Exception as e:\n",
        "        # Print error message if an exception occurs during file loading\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def read_multiple_files(file_paths):\n",
        "    # List to store loaded data from each file\n",
        "    loaded_data = []\n",
        "\n",
        "    # Use ThreadPoolExecutor to load files concurrently\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        # Submit load_data tasks for each file path\n",
        "        future_to_file = {executor.submit(load_data, file_path): file_path for file_path in file_paths}\n",
        "        # Process each future as it completes\n",
        "        for future in concurrent.futures.as_completed(future_to_file):\n",
        "            file_path = future_to_file[future]\n",
        "            try:\n",
        "                # Retrieve the result of the future\n",
        "                data = future.result()\n",
        "                # Add the data to loaded_data if it is not None\n",
        "                if data is not None:\n",
        "                    loaded_data.append(data)\n",
        "            except Exception as e:\n",
        "                # Print error message if an exception occurs during future execution\n",
        "                print(f\"Error loading {file_path}: {e}\")\n",
        "\n",
        "    return loaded_data\n",
        "\n",
        "def merge_files_side_by_side(file_paths):\n",
        "    # Read multiple files and get a list of DataFrames\n",
        "    dfs = read_multiple_files(file_paths)\n",
        "    # Filter out only DataFrames from the list\n",
        "    dfs = [df for df in dfs if isinstance(df, pd.DataFrame)]\n",
        "\n",
        "    # Handle the case with zero or one DataFrame\n",
        "    if len(dfs) == 0:\n",
        "        return None  # or raise an error, depending on desired behavior\n",
        "    elif len(dfs) == 1:\n",
        "        return dfs[0]\n",
        "\n",
        "    # Concatenate DataFrames side-by-side (i.e., column-wise)\n",
        "    merged_df = pd.concat(dfs, axis=1)\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "def get_file_paths_from_input():\n",
        "    # Prompt user for input and split by comma\n",
        "    file_paths = input(\"Enter file paths separated by commas: \").split(',')\n",
        "    # Strip any extra whitespace from each file path\n",
        "    file_paths = [file_path.strip() for file_path in file_paths]\n",
        "    return file_paths\n",
        "\n",
        "# Example usage\n",
        "file_paths = get_file_paths_from_input()  # Get the list of file paths from user input\n",
        "print(type(file_paths))\n",
        "\n",
        "if len(file_paths) > 1:\n",
        "    if_yes = input(\"Do you want to merge the files side-by-side? (yes/no): \")\n",
        "    if if_yes == \"yes\":\n",
        "        merged_df = merge_files_side_by_side(file_paths)  # Merge the files side-by-side\n",
        "        print(merged_df.head())\n",
        "    elif if_yes == \"no\":\n",
        "        x = read_multiple_files(file_paths)  # Read the files individually\n",
        "        for idx, file_data in enumerate(x):\n",
        "            variable_name = f\"file_{idx+1}\"\n",
        "            globals()[variable_name] = file_data\n",
        "            print(f\"{variable_name}:\\n{file_data}\\n\")\n",
        "else:\n",
        "    single_file = load_data(file_paths[0])  # Load the single file\n",
        "    print(single_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMrVxshxgiz3",
        "outputId": "2254942a-65ec-45ad-a3b9-79ca7345eac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}